*** the default unit is eV ***

1. 
please go to https://opencatalystproject.org/
to view and download the dataset
the ones used in this study is the S2EF 200k training dataset
and val_id validation dataset for test


2.
unzip the data to the directories:
training: ./s2ef_train_200K/s2ef_train_200K/
test:     ./s2ef_val_id/s2ef_val_id/

Note that please untar each data file to *.extxyz


3.
calculate per-element bias and prepare training data pickle using:
python OCP_read_train_dataset_linear_fit.py [trial_name]
for example
python OCP_read_train_dataset_linear_fit.py full_data

then test data
python OCP_read_train_dataset_linear_fit.py [trial_name] [val_dataset_name]
for example
python OCP_read_train_dataset_linear_fit.py full_data s2ef_val_id

Note that training data has to be prepared first for each trial


4.
train model with the following command:
python OCP_train_model_gpu.py [trial_name] [checkpoint_name] [num_gaussians] [order_MCSH] [num_nodes] [num_layers] [minibatch_size] [cutoff_distance] [num_training_points]
for example
python OCP_train_model_gpu.py full_data test 19 4 150 7 32 15.0 25000
to train a GMP(4,19)+SNN(150,7) model, with cutoff distance of 15.0 angstrom, 25000 training images and 32 image minibatch during training. 
Note that "test" is here as a placeholder, as no checkpoint is loaded

Due to the size of the systems, it's recommended to turn save_fps on if possible, so that features calculated are saved to disk, and can be loaded later

to load model and continue training from checkpoint, uncomment line 204 of the scipt and run something like
python train_model_gpu.py full_data ./checkpoints/2021-02-03-14-44-03-test 19 4 150 7 32 15.0

You can also change the list of sigmas in the script


5.
from line 308 of python OCP_train_model_gpu.py, the script runs a quick test with 25000 images in the training set that didn't use for training
please comment out or change as needed



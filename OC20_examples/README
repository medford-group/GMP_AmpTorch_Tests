*** the default unit is eV ***

Note that the per-element biases, and feature scalers are provided for the feature sets in this example
to generate models with other setups, please prepare the feature scaler with the example provided on 
AmpTorch website before calculating lmdb files 

1. 
please go to https://opencatalystproject.org/
to view and download the dataset
the ones used in this study is the S2EF 20M training dataset
and val_id validation dataset for test


2.
unzip the data to the directories:
training: ./s2ef_train_20M/s2ef_train_20M/
test:     ./s2ef_val_id/s2ef_val_id/

Note that please untar each data file to *.extxyz 
each file is a sub-dataset that contains the energy and coordinates of 50000 images


3.
Apply per-element bias and create list of images based on each sub-dataset
result will be saved at trial_data_full_20M/images

simply run 
python OCP_read_train_dataset_linear_fit_20M_prepare.py
for preparing the per-element bias, then
python OCP_read_train_dataset_linear_fit_20M.py

Note that this will apply to all the files by default, and could take a while
if you only want to train with a subset, change line 110 of the file


4.
Prepare lmdb files
once step 3 is finished, first prepare the feature/target normalizers of a certain descriptor set by

python generate_lmdb.py [num_radial_gaussian] [max_MCSH_order]

then prepare lmdb files for the GMP setup of choice using

python generate_lmdb.py [num_radial_gaussian] [max_MCSH_order] [sub_dataset_index]

e.g.
python generate_lmdb_init_scaler.py 30 2
python generate_lmdb.py 30 2 0

Note that this could take a while, so it's adviced to prepare the lmdb files in parallel if you can
 parallelize w.r.t. sub_dataset_index


similar for the validation set:
python generate_lmdb_val.py [num_radial_gaussian] [max_MCSH_order] [sub_dataset_index]


4.
Train Model!

train model with the following command:
python train_model_gpu_lmdb.py [trial_name] [checkpoint_name] [num_radial_gaussians] [max_MCSH_order] [NN_index] [num_training_data] [minibatch_size] [learning_rate] [num_epochs]

trail_num = sys.argv[1]
checkpoint_name = sys.argv[2]
​
nsigmas = int(sys.argv[3])
MCSHs_index = int(sys.argv[4])
NN_index = int(sys.argv[5])
num_data = int(sys.argv[6])
batch_size = int(sys.argv[7])
​
num_max_dataset = int(num_data / 50000)
lr = float(sys.argv[8])
epochs = int(sys.argv[9])
n_gpu = torch.cuda.device_count()

for example

python OCP_train_model_gpu.py data_full_20M test 30 2 3 25000 64 5e-3 2000

to train a GMP(30,2)+SNN(128,64,64) model, with cutoff distance of 15.0 angstrom, 25000 training images and 32 image minibatch during training. 
learning rate is 5e-3 and train for 2000 epochs


Note that "test" is here as a placeholder, as no checkpoint is loaded, provide full path here if you want to load checkpoint

python OCP_train_model_gpu.py data_full_20M ./checkpoints/2021-02-03-14-44-03-test 30 2 3 25000 64 5e-3 2000


